Value = c(1, 1.9)
)
data$Metric <- factor(data$Metric, levels = c("$1mn earnings", "$ effect on\n stock price"))
stock_earnings_plot <- create_stock_earnings_plot(data, 2.20, breaks = seq(0,2.20, by = 0.2), FALSE)
print(stock_earnings_plot)
ggsave(
file.path(dir, "two_conversion_rates", paste0("final_","D_earn",".png" )),
dpi=40,
width = 500,
height = 500,
units = "px")
data <- data.frame(
Metric = c("1 sentiment point", "$ effect on\n stock price"),
Value = c(1, 0.5)
)
data$Metric <- factor(data$Metric, levels = c("1 sentiment point", "$ effect on\n stock price"))
stock_earnings_plot <- create_stock_earnings_plot(data, 2.20, breaks = seq(0,2.20, by = 0.2), FALSE)
print(stock_earnings_plot)
ggsave(
file.path(dir, "two_conversion_rates", paste0("final_","D_sent",".png" )),
dpi=40,
width = 500,
height = 500,
units = "px")
for (i in c("A_earn", "B_earn", "C_earn", "D_earn",
"A_sent", "B_sent", "C_sent", "D_sent")) {
filename_input <-file.path(dir,"two_conversion_rates", paste0("final_",i,".png" ))
filename_output <- file.path(dir,"two_conversion_rates", paste0("final_",i,"_blurry.png" ))
print(i)
img <- image_read(filename_input)
blurred_img <- img %>%
image_convolve("Gaussian:0x100")
text_par <- "1 sentiment\n point"
cord_par <- "65"
if(grepl("earn", i)){
text_par <- "$1mn earnings"
cord_par <- "47"
}
blurred_img <- image_annotate(blurred_img, text_par, size = 25, color = "black", location = paste0("+", cord_par, "+430"))
blurred_img <- image_annotate(blurred_img, "$ effect on\n stock price", size = 25, color = "black", location = "+270+430")
img <- image_annotate(img, text_par, size = 25, color = "black", location = paste0("+", cord_par, "+430"))
img <- image_annotate(img, "$ effect on\n stock price", size = 25, color = "black", location = "+270+430")
image_write(blurred_img, filename_output)
image_write(img, filename_input)
}
#get pictures values
df <- read.csv(file.path(dir, "names.csv"), header = FALSE, col.names = c("name", "url"))
print(df)
write.csv(df,file.path(dir, "names_quotes.csv"), row.names = FALSE, quote = TRUE)
write_json(df,file.path(dir, "names.json"))
json_data <- fromJSON(file.path(dir, "names.json"))
json_string <- toJSON(json_data, pretty = TRUE)
rmarkdown::render('pilot_4.Rmd')
rmarkdown::render('Untitled.Rmd')
install.packages("knir")
install.packages("knitr")
install.packages("knitr")
# Create a dataframe with gallons of milk ranging from 0 to 100
data <- data.frame(gallons_of_milk = 0:1000/10)
# Calculate happiness (square root of gallons of milk)
data$healthiness <- data$gallons_of_milk * (200 -data$gallons_of_milk)
# Create a line plot with blue axes lines and larger axis labeling
g <- ggplot(data, aes(x = gallons_of_milk, y = healthiness)) +
geom_line(color = "blue", linewidth=2) +  # Change line color to blue
labs(x = "Gallons of healthy drink bought", y = "Health") +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_cartesian(x = c(0, 100), y = c(0, 10100)) +
geom_hline(yintercept = 0) +  # Change axes line color to blue
geom_vline(xintercept = 0) +  # Change axes line color to blue
theme_minimal() +
theme(panel.grid.major = element_blank(),  # Remove gridlines
panel.grid.minor = element_blank(),
axis.text = element_text(size = 20),  # Increase axis text size
axis.title = element_text(size = 24),
axis.ticks = element_line(),
plot.margin = margin(1, 1, 0.1, 0.1, "cm"))  # Increase axis title size
g
install.packages("ggplot2")
library(ggplot2)
# Create a dataframe with gallons of milk ranging from 0 to 100
data <- data.frame(gallons_of_milk = 0:1000/10)
# Calculate happiness (square root of gallons of milk)
data$healthiness <- data$gallons_of_milk * (200 -data$gallons_of_milk)
# Create a line plot with blue axes lines and larger axis labeling
g <- ggplot(data, aes(x = gallons_of_milk, y = healthiness)) +
geom_line(color = "blue", linewidth=2) +  # Change line color to blue
labs(x = "Gallons of healthy drink bought", y = "Health") +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_cartesian(x = c(0, 100), y = c(0, 10100)) +
geom_hline(yintercept = 0) +  # Change axes line color to blue
geom_vline(xintercept = 0) +  # Change axes line color to blue
theme_minimal() +
theme(panel.grid.major = element_blank(),  # Remove gridlines
panel.grid.minor = element_blank(),
axis.text = element_text(size = 20),  # Increase axis text size
axis.title = element_text(size = 24),
axis.ticks = element_line(),
plot.margin = margin(1, 1, 0.1, 0.1, "cm"))  # Increase axis title size
g
ggsave(paste0(dir,"PRO_health.png"),
g,# File name
width = 10,  # Width in inches
height = 6,  # Height in inches
dpi = 300)   # Resolution in dots per inch
dir <- "/Users/sebastianredl/Dropbox (Harvard University)/Attenuation/Instructions/figures/"
# Create a line plot with blue axes lines and larger axis labeling
g <- ggplot(data, aes(x = gallons_of_milk, y = healthiness)) +
geom_line(color = "blue", linewidth=2) +  # Change line color to blue
labs(x = "Gallons of healthy drink bought", y = "Health") +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
coord_cartesian(x = c(0, 100), y = c(0, 10100)) +
geom_hline(yintercept = 0) +  # Change axes line color to blue
geom_vline(xintercept = 0) +  # Change axes line color to blue
theme_minimal() +
theme(panel.grid.major = element_blank(),  # Remove gridlines
panel.grid.minor = element_blank(),
axis.text = element_text(size = 20),  # Increase axis text size
axis.title = element_text(size = 24),
axis.ticks = element_line(),
plot.margin = margin(1, 1, 0.1, 0.1, "cm"))  # Increase axis title size
g
ggsave(paste0(dir,"PRO_health.png"),
g,# File name
width = 10,  # Width in inches
height = 6,  # Height in inches
dpi = 300)   # Resolution in dots per inch
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
# Libraries -------------------------------------------------------------------
library(tidyr)
library(readr)
library(data.table)
library(stringr)
library(purrr)
library(jsonlite)
library(dplyr)
renv::update("dplyr") #or tidyr
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
# Libraries -------------------------------------------------------------------
library(tidyr)
library(readr)
library(data.table)
library(stringr)
library(purrr)
library(jsonlite)
library(dplyr)
renv::update("tidyr")
renv::update("dplyr")
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
# Libraries -------------------------------------------------------------------
library(tidyr)
library(readr)
library(data.table)
library(stringr)
library(purrr)
library(jsonlite)
library(dplyr)
renv::update("dplyr"
)
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
# Libraries -------------------------------------------------------------------
library(tidyr)
library(readr)
library(data.table)
library(stringr)
library(purrr)
library(jsonlite)
library(dplyr)
renv::update("tidyr")
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
# Libraries -------------------------------------------------------------------
library(tidyr)
library(readr)
library(data.table)
library(stringr)
library(purrr)
library(jsonlite)
library(dplyr)
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
################################################################################
################################################################################
# D A T A    R A W    P R O C E S S I N G    F I L E #
################################################################################
################################################################################
# Gold of this file are three fold:
# 1) filter for relevant subjects
#
# 2) bring raw format into long format.
# Specifically, this means:
#    - each task produces the following columns which we need for the analysis:
#       * "par1", "par2", "par3": parameterization columns of the task
#       * "response1", "response2", "response3": response columns of the tasks
#      -> this can be the literal input or which auxilliary parameter appeared
#       * "cu", "time": cognitive uncertainty and time
#       * "order_tasks", "order_tasks2": randomized order of the main parameter and order_tasks2 for the REC task
#    - A raw data cell in these columns look like the following:
#     "ENS:12000,4000,6000,3000,10000,13000,8000,14000,5000,2000,11000", where
#       * "ENS" is the task name
#       * 12000", the parameter in the first round
#       * 4000", the parameter in the second round
#       * ....
#       !Important: number of rounds can differ across task! number of rounds is reported in a separat columns!
#    - We want to have it in the long format:
#     task | round | parameter | response | cu | time | order
#     ENS  |   1   |  12000    |    ...   | .. | ...  | ...
#     ENS  |   2   |  4000     |    ...   | .. | ...  | ...
#     ENS  |   3   |  6000     |    ...   | .. | ...  | ...
#     ENS  |   4   |  3000     |    ...   | .. | ...  | ...
#     ENS  |   5   |  10000    |    ...   | .. | ...  | ...
#     ENS  |   6   |  13000    |    ...   | .. | ...  | ...
#
# 3) save other information such as comprehension question failures or calculator usage
#
### This file
PATH <- "/Users/sebastianredl/Dropbox (Harvard University)/Attenuation"
setwd(path)
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
################################################################################
################################################################################
# D A T A    R A W    P R O C E S S I N G    F I L E #
################################################################################
################################################################################
# Gold of this file are three fold:
# 1) filter for relevant subjects
#
# 2) bring raw format into long format.
# Specifically, this means:
#    - each task produces the following columns which we need for the analysis:
#       * "par1", "par2", "par3": parameterization columns of the task
#       * "response1", "response2", "response3": response columns of the tasks
#      -> this can be the literal input or which auxilliary parameter appeared
#       * "cu", "time": cognitive uncertainty and time
#       * "order_tasks", "order_tasks2": randomized order of the main parameter and order_tasks2 for the REC task
#    - A raw data cell in these columns look like the following:
#     "ENS:12000,4000,6000,3000,10000,13000,8000,14000,5000,2000,11000", where
#       * "ENS" is the task name
#       * 12000", the parameter in the first round
#       * 4000", the parameter in the second round
#       * ....
#       !Important: number of rounds can differ across task! number of rounds is reported in a separat columns!
#    - We want to have it in the long format:
#     task | round | parameter | response | cu | time | order
#     ENS  |   1   |  12000    |    ...   | .. | ...  | ...
#     ENS  |   2   |  4000     |    ...   | .. | ...  | ...
#     ENS  |   3   |  6000     |    ...   | .. | ...  | ...
#     ENS  |   4   |  3000     |    ...   | .. | ...  | ...
#     ENS  |   5   |  10000    |    ...   | .. | ...  | ...
#     ENS  |   6   |  13000    |    ...   | .. | ...  | ...
#
# 3) save other information such as comprehension question failures or calculator usage
#
### This file
PATH <- "/Users/sebastianredl/Dropbox (Harvard University)/Attenuation"
setwd(PATH)
path_data<- "Analyses/Data"
analysis_name <- "main_run"
path_input <- file.path(path_data,paste0(analysis_name, ".csv"))# raw data input
path_output_clean <- file.path(path_data,paste0(analysis_name,"_qualtrics_clean", ".csv")) # clean data output
path_output_fig <- file.path("Analyses/R Code/output", analysis_name) # output figures
path_output_bonus <- file.path(path_data,"bonus", analysis_name) # output bonus
path_output_completion <- file.path(path_data,"completion_fee", analysis_name) # output completion fee approvals
path_output_power <- file.path("Analyses/R Code/output", analysis_name,"power") # output power analysis
path_output_demog <- file.path(path_data,"demographics", analysis_name)
# creating directories
if (!file.exists(path_output_fig)){
dir.create(path_output_fig, recursive = TRUE)
print(paste("Directory", path_output_fig, "created."))
}
path_output_fig
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
################################################################################
################################################################################
# D A T A    R A W    P R O C E S S I N G    F I L E #
################################################################################
################################################################################
# Gold of this file are three fold:
# 1) filter for relevant subjects
#
# 2) bring raw format into long format.
# Specifically, this means:
#    - each task produces the following columns which we need for the analysis:
#       * "par1", "par2", "par3": parameterization columns of the task
#       * "response1", "response2", "response3": response columns of the tasks
#      -> this can be the literal input or which auxilliary parameter appeared
#       * "cu", "time": cognitive uncertainty and time
#       * "order_tasks", "order_tasks2": randomized order of the main parameter and order_tasks2 for the REC task
#    - A raw data cell in these columns look like the following:
#     "ENS:12000,4000,6000,3000,10000,13000,8000,14000,5000,2000,11000", where
#       * "ENS" is the task name
#       * 12000", the parameter in the first round
#       * 4000", the parameter in the second round
#       * ....
#       !Important: number of rounds can differ across task! number of rounds is reported in a separat columns!
#    - We want to have it in the long format:
#     task | round | parameter | response | cu | time | order
#     ENS  |   1   |  12000    |    ...   | .. | ...  | ...
#     ENS  |   2   |  4000     |    ...   | .. | ...  | ...
#     ENS  |   3   |  6000     |    ...   | .. | ...  | ...
#     ENS  |   4   |  3000     |    ...   | .. | ...  | ...
#     ENS  |   5   |  10000    |    ...   | .. | ...  | ...
#     ENS  |   6   |  13000    |    ...   | .. | ...  | ...
#
# 3) save other information such as comprehension question failures or calculator usage
#
### This file
PATH <- "/Users/sebastianredl/Dropbox (Harvard University)/Attenuation"
setwd(PATH)
path_data<- "Analyses/Data"
analysis_name <- "main_run"
path_input <- file.path(path_data,paste0(analysis_name, ".csv"))# raw data input
path_output_clean <- file.path(path_data,paste0(analysis_name,"_qualtrics_clean", ".csv")) # clean data output
path_output_fig <- file.path("Analyses/Results", analysis_name) # output figures
path_output_bonus <- file.path(path_data,"bonus", analysis_name) # output bonus
path_output_completion <- file.path(path_data,"completion_fee", analysis_name) # output completion fee approvals
path_output_power <- file.path("Analyses/R Code/output", analysis_name,"power") # output power analysis
path_output_demog <- file.path(path_data,"demographics", analysis_name)
# creating directories
if (!file.exists(path_output_fig)){
dir.create(path_output_fig, recursive = TRUE)
print(paste("Directory", path_output_fig, "created."))
}
if (!file.exists(path_output_bonus)){
dir.create(path_output_bonus, recursive = TRUE)
print(paste("Directory", path_output_bonus, "created."))
}
if (!file.exists(path_output_completion)){
dir.create(path_output_completion, recursive = TRUE)
print(paste("Directory", path_output_completion, "created."))
}
if (!file.exists(path_output_completion)){
dir.create(path_output_completion, recursive = TRUE)
print(paste("Directory", path_output_completion, "created."))
}
headers <- read.csv(path_input, header = FALSE, nrows = 1, as.is = TRUE)
data_raw <- read.csv(path_input, skip = 3, header = FALSE)
colnames(data_raw) <- headers
data_filtered_all_col <- data_raw %>%
filter(
mobile_screened == 0,
compcheck2_failed != 1,
compcheck2_failed_task2 != 1,
no_consent == 0,
Finished == "True",
Progress == 100,
!(((as.numeric(gpt_pasta) == 1) | (as.numeric(gpt_rice) == 1)) | (as.numeric(gpt_coffee) == 1)),
(url_correct == 1), #remove people that chnage the URL
PROLIFIC_PID != "65032c0e9f8649f89c39327e",#thomas prolific id
PROLIFIC_PID != "6627c14abd2692998a9192f6", #my prolific id
PROLIFIC_PID != "65abf2d64c8491a1bb904917", #weird guy
PROLIFIC_PID != "", #empty prolific id
PROLIFIC_PID != "5c63323db73d590001ae79be", #this guy returned the MUL study even thoguh completed
PROLIFIC_PID != "601fe0de101ae05414812f4d", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely. task ENS
PROLIFIC_PID != "597519f8262c480001bbaf8b", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely task PRS
PROLIFIC_PID != "5c882fbb42ff490016c7e47b", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely task ENS
PROLIFIC_PID != "5c873649fff8430016e9aa7a", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely task NEW
PROLIFIC_PID != "589ce4d65e63bf00013b3175", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely. task PRE
PROLIFIC_PID != "66598996c0d394acecbfb4ba", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely. task FOR
PROLIFIC_PID != "65f18be05e1d10cb4d87b336", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely task SEA
PROLIFIC_PID != "6553e12c3b83480e8318225b", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely task PRS
PROLIFIC_PID != "60f8b9a76a790915df2557ff", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely task REC
PROLIFIC_PID != "5f2eebd9d21e322a9ed68f09", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely task TAX
PROLIFIC_PID != "628690801339eca9c44143cd", #this guy  has one of his responses NAN. I dont know how he did it but removed him completely task CHT
PROLIFIC_PID != "5f4e79fc592a74059a7a9786", #this guy  is in EGI and BEU
PROLIFIC_PID != "5d2fabf8cbcda30001d27a68", #this guy  has no response in round 11 PGG
PROLIFIC_PID != "60a523855e265d3b7e3c7853", #this guyhas no response in round 11 PGG
!(PROLIFIC_PID %in% ##these did not have any observations, these were mainly SEA...
c("63ea4ab1ce4168cbe9f63775", "66200b032829f40f3664afdf", "5c366fc38821900001b38b67", "66130b23ee407564e718fcfd", "660465471aeb130a6ade4f2f", "6644a34a576e8e69578cca1b",
"653d144d2e894446d55babdb", "65ea13623d17ab5e238ee93f", "5d4a6459061e2a000138bad3", "59ffb939517dfb00013dadda", "5af1f7c26c584b0001bc2140", "65ebbbc0a6328372037a40c1",
"5f511ab38505ac2e8fbfac5e", "58b20110c2cfc500016b11c7", "6646653dc67583efb71e96cf")),
!((tasks == "EGI")&(survey_version=="26")),
!((tasks == "PGG")&(survey_version=="28")),### remove pilot data
) %>%
rename(id =  PROLIFIC_PID)
rm(list = ls())
# -----------------------------------------------------------------------------
renv::load(here::here())
################################################################################
################################################################################
# D A T A    R A W    P R O C E S S I N G    F I L E #
################################################################################
################################################################################
# Gold of this file are three fold:
# 1) filter for relevant subjects
#
# 2) bring raw format into long format.
# Specifically, this means:
#    - each task produces the following columns which we need for the analysis:
#       * "par1", "par2", "par3": parameterization columns of the task
#       * "response1", "response2", "response3": response columns of the tasks
#      -> this can be the literal input or which auxilliary parameter appeared
#       * "cu", "time": cognitive uncertainty and time
#       * "order_tasks", "order_tasks2": randomized order of the main parameter and order_tasks2 for the REC task
#    - A raw data cell in these columns look like the following:
#     "ENS:12000,4000,6000,3000,10000,13000,8000,14000,5000,2000,11000", where
#       * "ENS" is the task name
#       * 12000", the parameter in the first round
#       * 4000", the parameter in the second round
#       * ....
#       !Important: number of rounds can differ across task! number of rounds is reported in a separat columns!
#    - We want to have it in the long format:
#     task | round | parameter | response | cu | time | order
#     ENS  |   1   |  12000    |    ...   | .. | ...  | ...
#     ENS  |   2   |  4000     |    ...   | .. | ...  | ...
#     ENS  |   3   |  6000     |    ...   | .. | ...  | ...
#     ENS  |   4   |  3000     |    ...   | .. | ...  | ...
#     ENS  |   5   |  10000    |    ...   | .. | ...  | ...
#     ENS  |   6   |  13000    |    ...   | .. | ...  | ...
#
# 3) save other information such as comprehension question failures or calculator usage
#
### setting directories
PATH <- "/Users/sebastianredl/Dropbox (Harvard University)/Attenuation"
setwd(PATH)
path_data<- "Analyses/Data"
analysis_name <- "main_run"
path_input <- file.path(path_data,paste0(analysis_name, ".csv"))# raw data input
path_output_clean <- file.path(path_data,paste0(analysis_name,"_qualtrics_clean", ".csv")) # clean data output
path_output_fig <- file.path("Analyses/Results", analysis_name) # output figures
path_output_bonus <- file.path(path_data,"bonus", analysis_name) # output bonus
path_output_completion <- file.path(path_data,"completion_fee", analysis_name) # output completion fee approvals
path_output_power <- file.path("Analyses/R Code/output", analysis_name,"power") # output power analysis
path_output_demog <- file.path(path_data,"demographics", analysis_name)
# creating directories
if (!file.exists(path_output_fig)){
dir.create(path_output_fig, recursive = TRUE)
print(paste("Directory", path_output_fig, "created."))
}
if (!file.exists(path_output_bonus)){
dir.create(path_output_bonus, recursive = TRUE)
print(paste("Directory", path_output_bonus, "created."))
}
if (!file.exists(path_output_completion)){
dir.create(path_output_completion, recursive = TRUE)
print(paste("Directory", path_output_completion, "created."))
}
if (!file.exists(path_output_completion)){
dir.create(path_output_completion, recursive = TRUE)
print(paste("Directory", path_output_completion, "created."))
}
# ==============================================================================
##################  Step 1) filter for relevant subjects #######################
# ==============================================================================
# loading raw data
headers <- read.csv(path_input, header = FALSE, nrows = 1, as.is = TRUE)
data_raw <- read.csv(path_input, skip = 3, header = FALSE)
colnames(data_raw) <- headers
#filter data
data_filtered_all_col <- data_raw %>%
filter(
mobile_screened == 0,
compcheck2_failed != 1,
compcheck2_failed_task2 != 1,
no_consent == 0,
Finished == "True",
Progress == 100,
!(((as.numeric(gpt_pasta) == 1) | (as.numeric(gpt_rice) == 1)) | (as.numeric(gpt_coffee) == 1)),
(url_correct == 1), #remove people that chnage the URL
PROLIFIC_PID != "65032c0e9f8649f89c39327e",#thomas prolific id
PROLIFIC_PID != "6627c14abd2692998a9192f6", #my prolific id
PROLIFIC_PID != "65abf2d64c8491a1bb904917", #weird guy
PROLIFIC_PID != "", #empty prolific id
PROLIFIC_PID != "5c63323db73d590001ae79be", #this guy returned the MUL study even thoguh completed
PROLIFIC_PID != "601fe0de101ae05414812f4d", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: ENS
PROLIFIC_PID != "597519f8262c480001bbaf8b", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: PRS
PROLIFIC_PID != "5c882fbb42ff490016c7e47b", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: ENS
PROLIFIC_PID != "5c873649fff8430016e9aa7a", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: NEW
PROLIFIC_PID != "589ce4d65e63bf00013b3175", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: PRE
PROLIFIC_PID != "66598996c0d394acecbfb4ba", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: FOR
PROLIFIC_PID != "65f18be05e1d10cb4d87b336", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: SEA
PROLIFIC_PID != "6553e12c3b83480e8318225b", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: PRS
PROLIFIC_PID != "60f8b9a76a790915df2557ff", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: REC
PROLIFIC_PID != "5f2eebd9d21e322a9ed68f09", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: TAX
PROLIFIC_PID != "628690801339eca9c44143cd", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: CHT
PROLIFIC_PID != "5f4e79fc592a74059a7a9786", #this guy  is in EGI and BEU at the same time (because some one shared the link?) -> completely removed
PROLIFIC_PID != "5d2fabf8cbcda30001d27a68", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: PGG
PROLIFIC_PID != "60a523855e265d3b7e3c7853", #this guy  has one of his responses NAN. I dont know how s/he did it but removed that person completely. task: PGG
!(PROLIFIC_PID %in% ##these did not have any observations, these were mainly SEA...
c("63ea4ab1ce4168cbe9f63775", "66200b032829f40f3664afdf", "5c366fc38821900001b38b67", "66130b23ee407564e718fcfd", "660465471aeb130a6ade4f2f", "6644a34a576e8e69578cca1b",
"653d144d2e894446d55babdb", "65ea13623d17ab5e238ee93f", "5d4a6459061e2a000138bad3", "59ffb939517dfb00013dadda", "5af1f7c26c584b0001bc2140", "65ebbbc0a6328372037a40c1",
"5f511ab38505ac2e8fbfac5e", "58b20110c2cfc500016b11c7", "6646653dc67583efb71e96cf")),
!((tasks == "EGI")&(survey_version=="26")), ### remove pilot data from EGI
!((tasks == "PGG")&(survey_version=="28")), ### remove pilot data from PGG
) %>%
rename(id =  PROLIFIC_PID)
rm(list = ls())
# -----------------------------------------------------------------------------
#renv::load(here::here())
library(tidyr)
library(readr)
# library(data.table)
# library(stringr)
# library(purrr)
library(jsonlite)
library(dplyr)
