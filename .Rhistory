# Create a second vector of equal length with 1 in every row
t_values_SE <- rep(1, length(sorted_t_values)) # All t-values have SE 1
scale_parameter_t <- tau_prior_scale # Set the scale of the half-normal prior distribution on parameter Tau
# Run the bayesian meta-analysis via the bayesmeta function.
bma_t <- bayesmeta (y=t_values_df_model1$t_value, sigma=t_values_SE,
tau.prior=function (t) {dhalfnormal (t, scale=scale_parameter_t) })
# Save the estimates for the tau heterogeneity parameter
mean_tau_t_model1 <- round(bma_t$summary["mean", "tau"], 2) # this is the tau that was determined by the model
empiric_tau_t_model1 <- round(sqrt(var(t_values_df_model1$t_value)), 2) # this is the non-bayesian tau that's the empirical heterogeneity
# Initialize an empty dataframe to store posterior summaries
t_posterior_summary_df <- data.frame(
Experiment = character(),
y = numeric(),
sigma = numeric(),
mode = numeric(),
median = numeric(),
mean = numeric(),
sd = numeric(),
lower_95 = numeric(),
upper_95 = numeric(),
stringsAsFactors = FALSE
)
# Loop through each experiment in sorted_t_values_labels
for (experiment_label in sorted_t_values_labels) {
# Check if the experiment label exists
if (experiment_label %in% sorted_t_values_labels) {
label_index <- which(sorted_t_values_labels == experiment_label)
# Extract the posterior summary
summary_data <- bma_t$theta[, label_index]
# Append the data to the dataframe
t_posterior_summary_df <- rbind(t_posterior_summary_df, data.frame(
Experiment = experiment_label,
y = summary_data["y"],
sigma = summary_data["sigma"],
mode = summary_data["mode"],
median = summary_data["median"],
mean = summary_data["mean"],
sd = summary_data["sd"],
lower_95 = summary_data["95% lower"],
upper_95 = summary_data["95% upper"]
))
}
}
# Create the data for the prior forest plot
y_ci_lower <- t_posterior_summary_df$y - 1.96 * t_posterior_summary_df$sigma
y_ci_upper <- t_posterior_summary_df$y + 1.96 * t_posterior_summary_df$sigma
# Prior estimates
prior_estimates_t <- data.frame(
task = t_posterior_summary_df$Experiment,
type = "Prior",
estimate = t_posterior_summary_df$y, # get the input y values
lower = y_ci_lower,
upper = y_ci_upper
)
# Posterior estimates
posterior_estimates_t <- data.frame(
task = t_posterior_summary_df$Experiment,
type = "Posterior",
estimate = t_posterior_summary_df$mean, # get the mean estimate for the posterior y estimate
lower = t_posterior_summary_df$lower_95, # get the posterior confidence interval
upper = t_posterior_summary_df$upper_95
)
# Combine prior and posterior estimates
combined_estimates_t_model1 <- bind_rows(prior_estimates_t, posterior_estimates_t)
# Reverse order by 'Prior' estimate
combined_estimates_t_model1 <- combined_estimates_t_model1 %>%
arrange(if_else(type == "Prior", estimate, NA_real_)) %>%
mutate(task = factor(task, levels = unique(task)))
#### 3.3. Meta-Analysis for par_n:dist_bound_n t-values ####
# Order the dataframe by the value of t_values
t_values_df_model2 <- t_values_df_model2[order(-t_values_df_model2$t_value), ]
# Create vectors from the sorted dataframe
sorted_t_values_model2 <- t_values_df_model2$t_value
sorted_t_values_labels_model2 <- t_values_df_model2$Task
# Create a second vector of equal length with 1 in every row
t_values_SE_model2 <- rep(1, length(t_values_df_model2$t_value))
scale_parameter_t_model2 <- tau_prior_scale  # Set the scale of the half-normal prior distribution on parameter Tau
# Run the bayesian meta-analysis for model2 t-values
bma_t_model2 <- bayesmeta(y = t_values_df_model2$t_value, sigma = t_values_SE_model2,
tau.prior = function (t) { dhalfnormal(t, scale = scale_parameter_t_model2) })
# Save the estimates for the heterogeneity parameter tau
mean_tau_t_model2 <- round(bma_t_model2$summary["mean", "tau"], 2)
empiric_tau_t_model2 <- round(sqrt(var(t_values_df_model2$t_value)), 2)
# Initialize an empty dataframe to store posterior summaries for model2
t_posterior_summary_df_model2 <- data.frame(
Experiment = character(),
y = numeric(),
sigma = numeric(),
mode = numeric(),
median = numeric(),
mean = numeric(),
sd = numeric(),
lower_95 = numeric(),
upper_95 = numeric(),
stringsAsFactors = FALSE
)
# Loop through each experiment in sorted_t_values_labels_model2
for (experiment_label in sorted_t_values_labels_model2) {
# Check if the experiment label exists
if (experiment_label %in% sorted_t_values_labels_model2) {
label_index <- which(sorted_t_values_labels_model2 == experiment_label)
# Extract the posterior summary
summary_data <- bma_t_model2$theta[, label_index]
# Append the data to the dataframe
t_posterior_summary_df_model2 <- rbind(t_posterior_summary_df_model2, data.frame(
Experiment = experiment_label,
y = summary_data["y"],
sigma = summary_data["sigma"],
mode = summary_data["mode"],
median = summary_data["median"],
mean = summary_data["mean"],
sd = summary_data["sd"],
lower_95 = summary_data["95% lower"],
upper_95 = summary_data["95% upper"]
))
}
}
# Create the data for the prior forest plot for model2
y_ci_lower_model2 <- t_posterior_summary_df_model2$y - 1.96 * t_posterior_summary_df_model2$sigma
y_ci_upper_model2 <- t_posterior_summary_df_model2$y + 1.96 * t_posterior_summary_df_model2$sigma
# Prior estimates for model2
prior_estimates_t_model2 <- data.frame(
task = t_posterior_summary_df_model2$Experiment,
type = "Prior",
estimate = t_posterior_summary_df_model2$y,
lower = y_ci_lower_model2,
upper = y_ci_upper_model2
)
# Posterior estimates for model2
posterior_estimates_t_model2 <- data.frame(
task = t_posterior_summary_df_model2$Experiment,
type = "Posterior",
estimate = t_posterior_summary_df_model2$mean,
lower = t_posterior_summary_df_model2$lower_95,
upper = t_posterior_summary_df_model2$upper_95
)
# Combine prior and posterior estimates for model2
combined_estimates_t_model2 <- bind_rows(prior_estimates_t_model2, posterior_estimates_t_model2)
# Remove rows with NA in 'estimate' column
combined_estimates_t_model2 <- combined_estimates_t_model2 %>% filter(!is.na(estimate))
# Order by 'Prior' estimate
combined_estimates_t_model2 <- combined_estimates_t_model2 %>%
arrange(if_else(type == "Prior", estimate, NA_real_)) %>%
mutate(task = factor(task, levels = unique(task)))
#### 3.4. Meta-Analysis for phi_e estimates   ####
# Order the dataframe by the value of phi_e
temp_phi_e_estimate <- temp_phi_e_estimate[order(temp_phi_e_estimate$Coefficient), ]
phi_e <- temp_phi_e_estimate$Coefficient
phi_e_SE <- temp_phi_e_estimate$SE
phi_e_labels <- temp_phi_e_estimate$Task
scale_parameter_phi <- tau_prior_scale*10 # We multiply by ten (tau_squared is scaled by 100) since the phi_e parameter is rescaled times 100
# Run the bayesian meta-analysis
bma_phi_e <- bayesmeta (y=temp_phi_e_estimate$Coefficient, sigma=temp_phi_e_estimate$SE,
tau.prior=function (t) {dhalfnormal (t, scale=scale_parameter_phi) })
# Save the heterogeneity parameter estimates tau
mean_tau_phi <- round(bma_phi_e$summary["mean", "tau"], 2)
empiric_tau_phi <- round(sqrt(var(temp_phi_e_estimate$Coefficient)), 2)
# Initialize an empty dataframe to store posterior summaries
phi_e_posterior_summary_df <- data.frame(
Experiment = character(),
y = numeric(),
sigma = numeric(),
mode = numeric(),
median = numeric(),
mean = numeric(),
sd = numeric(),
lower_95 = numeric(),
upper_95 = numeric(),
stringsAsFactors = FALSE
)
# Loop through each experiment in sorted_phi_e_labels
for (experiment_label in phi_e_labels) {
# Check if the experiment label exists
if (experiment_label %in% phi_e_labels) {
label_index <- which(phi_e_labels == experiment_label)
# Extract the posterior summary
summary_data <- bma_phi_e$theta[, label_index]
# Append the data to the dataframe
phi_e_posterior_summary_df <- rbind(phi_e_posterior_summary_df, data.frame(
Experiment = experiment_label,
y = summary_data["y"],
sigma = summary_data["sigma"],
mode = summary_data["mode"],
median = summary_data["median"],
mean = summary_data["mean"],
sd = summary_data["sd"],
lower_95 = summary_data["95% lower"],
upper_95 = summary_data["95% upper"]
))
} else {
print(paste("Experiment label", experiment_label, "not found in the data."))
}
}
# Initialize an empty dataframe to store posterior summaries
phi_e_posterior_summary_df <- data.frame(
Experiment = character(),
y = numeric(),
sigma = numeric(),
mode = numeric(),
median = numeric(),
mean = numeric(),
sd = numeric(),
lower_95 = numeric(),
upper_95 = numeric(),
stringsAsFactors = FALSE
)
# Loop through each experiment in phi_e_labels
for (experiment_label in phi_e_labels) {
# Check if the experiment label exists
if (experiment_label %in% phi_e_labels) {
label_index <- which(phi_e_labels == experiment_label)
# Extract the posterior summary
summary_data <- bma_phi_e$theta[, label_index]
# Append the data to the dataframe
phi_e_posterior_summary_df <- rbind(phi_e_posterior_summary_df, data.frame(
Experiment = experiment_label,
y = summary_data["y"],
sigma = summary_data["sigma"],
mode = summary_data["mode"],
median = summary_data["median"],
mean = summary_data["mean"],
sd = summary_data["sd"],
lower_95 = summary_data["95% lower"],
upper_95 = summary_data["95% upper"]
))
}
}
# Create the data for the prior forest plot
y_ci_lower <- phi_e_posterior_summary_df$y - 1.96 * phi_e_posterior_summary_df$sigma
y_ci_upper <- phi_e_posterior_summary_df$y + 1.96 * phi_e_posterior_summary_df$sigma
# Prior estimates
prior_estimates_phi <- data.frame(
task = phi_e_posterior_summary_df$Experiment,
type = "Prior",
estimate = phi_e_posterior_summary_df$y,
lower = y_ci_lower,
upper = y_ci_upper
)
# Posterior estimates
posterior_estimates_phi <- data.frame(
task = phi_e_posterior_summary_df$Experiment,
type = "Posterior",
estimate = phi_e_posterior_summary_df$mean,
lower = phi_e_posterior_summary_df$lower_95,
upper = phi_e_posterior_summary_df$upper_95
)
# Combine prior and posterior estimates
combined_estimates_phi <- bind_rows(prior_estimates_phi, posterior_estimates_phi)
# Order by 'Prior' estimate
# Reverse order by 'Prior' estimate
combined_estimates_phi <- combined_estimates_phi %>%
arrange(if_else(type == "Prior", desc(estimate), NA_real_)) %>%
mutate(task = factor(task, levels = unique(task)))
#### 3.5. Meta-Analysis for estimated vs. rational beta ####
# We order the dataframe
model3_beta_estimates <- model3_beta_estimates[order(model3_beta_estimates$Estimate), ]
scale_parameter_rational <- tau_prior_scale
# Create the bma_rational object
bma_rational <- bayesmeta(
y = model3_beta_estimates$Estimate,
sigma = model3_beta_estimates$SE,
tau.prior = function(t) { dhalfnormal(t, scale = scale_parameter_rational) }  # Example prior, adjust as necessary
)
# Save the heterogeneity estimates
empiric_tau_rational <- round(sqrt(var(model3_beta_estimates$Estimate)), 2)
mean_tau_rational <- round(bma_rational$summary["mean", "tau"], 2)
# Extract posterior summary
posterior_summary_df <- data.frame(
Task = model3_beta_estimates$Task,
y = bma_rational$theta["y", ],
sigma = bma_rational$theta["sigma", ],
mode = bma_rational$theta["mode", ],
median = bma_rational$theta["median", ],
mean = bma_rational$theta["mean", ],
sd = bma_rational$theta["sd", ],
lower_95 = bma_rational$theta["95% lower", ],
upper_95 = bma_rational$theta["95% upper", ]
)
# Create the data for the prior forest plot
y_ci_lower <- model3_beta_estimates$CI_Lower
y_ci_upper <- model3_beta_estimates$CI_Upper
# Prior estimates
prior_estimates <- data.frame(
task = model3_beta_estimates$Task,
type = "Prior",
estimate = model3_beta_estimates$Estimate,
lower = y_ci_lower,
upper = y_ci_upper
)
# Posterior estimates
posterior_estimates <- data.frame(
task = model3_beta_estimates$Task,
type = "Posterior",
estimate = posterior_summary_df$mean,
lower = posterior_summary_df$lower_95,
upper = posterior_summary_df$upper_95
)
# Combine prior and posterior estimates
combined_estimates_rational_beta <- bind_rows(prior_estimates, posterior_estimates)
# Order by 'Prior' estimate
combined_estimates_rational_beta <- combined_estimates_rational_beta %>%
arrange(if_else(type == "Prior", estimate, NA_real_)) %>%
mutate(task = factor(task, levels = unique(task)))
#### 3.6. Packaging -- Saving all estimated objects ####
# Create the tau_info dataframe for this iteration
tau_info <- data.frame(
Model = c("model1", "model2", "phi", "rational"),
Bayesian_Tau = c(mean_tau_t_model1, mean_tau_t_model2, mean_tau_phi, mean_tau_rational),
Empiric_Tau = c(empiric_tau_t_model1, empiric_tau_t_model2, empiric_tau_phi, empiric_tau_rational)
)
# Assign the combined dataframes to the appropriate subset in df_bayesian_meta_analysis
if (subset == 1) {
df_bayesian_meta_analysis$subset1 <- create_subset_df()
} else if (subset == 2) {
df_bayesian_meta_analysis$subset2 <- create_subset_df()
} else if (subset == 3) {
df_bayesian_meta_analysis$subset3 <- create_subset_df()
}
# Clean up the workspace of all objects we no longer need:
# List of objects to delete
objects_to_delete <- c(
"beta_estimate", "bma_phi_e",
"bma_rational", "bma_t", "bma_t_model2", "ci_lower",
"ci_upper", "coef_model1", "coefficients_renamed", "coeftest_result",
"coeftest_result1", "coeftest_result2", "coeftest_result3", "combined_estimates_phi",
"combined_estimates_rational_beta", "combined_estimates_t_model1", "combined_estimates_t_model2",
"empiric_tau_phi", "empiric_tau_rational", "empiric_tau_t_model1", "empiric_tau_t_model2",
"experiment_label", "label_index", "mean_tau_phi", "mean_tau_rational",
"mean_tau_t_model1", "mean_tau_t_model2", "model1", "model2",
"model3", "model3_beta_estimates",
"phi_e", "phi_e_labels", "phi_e_posterior_summary_df",
"phi_e_SE", "phi_formula", "posterior_estimates", "posterior_estimates_phi",
"posterior_estimates_t", "posterior_estimates_t_model2", "posterior_summary_df", "prior_estimates",
"prior_estimates_phi", "prior_estimates_t", "prior_estimates_t_model2",
"scale_parameter_phi", "scale_parameter_rational", "scale_parameter_t", "scale_parameter_t_model2",
"se_estimate", "sens", "sorted_t_values",
"sorted_t_values_labels", "sorted_t_values_labels_model2", "sorted_t_values_model2", "subset",
"summary_data", "t_posterior_summary_df", "t_posterior_summary_df_model2", "t_value_model1",
"t_value_model2", "t_values_df_model1", "t_values_df_model2", "t_values_labels_model1",
"t_values_labels_model2", "t_values_model1", "t_values_model2", "t_values_SE",
"t_values_SE_model2", "task",
"tau_info", "temp_coeftest_results_model1", "temp_coeftest_results_model2",
"temp_coeftest_results_model3", "temp_current_data", "temp_filtered_data", "temp_filtered_data2",
"temp_phi_e_estimate", "vcov_renamed", "vcov1",
"vcov2", "vcov3", "y_ci_lower", "y_ci_lower_model2",
"y_ci_upper", "y_ci_upper_model2"
)
# Remove the listed objects from the workspace
rm(list = objects_to_delete)
}
rm(list = c("objects_to_delete", "df_temp", "temp_beta_by_respondent", "temp_sd_by_respondent"))
#### 4 Output Example usage: ####
# First, you pick which subset you want to visualize:
# subset==1: no subsetting other than the 6 outliers flagged by sebastian and removal of observations where par_n is at the lb and ub
# subset==2: excluding those whose SD of decisions is 0
# subset==3: excluding those for who the beta of resp_n on par_n is beta<= 0
# Define the subset number
subset <- 1
# Function to dynamically select subset data based on the subset number
get_subset_data <- function(df, subset) {
if (subset == 1) {
return(df$subset1)
} else if (subset == 2) {
return(df$subset2)
} else if (subset == 3) {
return(df$subset3)
} else {
stop("Invalid subset number")
}
}
# Extract the subset data from bayesian_meta_analysis based on the subset number
subset_data <- get_subset_data(df_bayesian_meta_analysis, subset)
# Unpack the combined dataframes from subset1
combined_estimates_t_model1 <- subset_data$combined_estimates_t_model1
combined_estimates_t_model2 <- subset_data$combined_estimates_t_model2
combined_estimates_phi <- subset_data$combined_estimates_phi
combined_estimates_rational_beta <- subset_data$combined_estimates_rational_beta
# Create single-row data frames for the labels for tau values
create_label_data <- function(tau_info, index) {
data.frame(
x = -Inf,
y = Inf,
label = paste("Bayesian Tau: ", tau_info$Bayesian_Tau[index],
"\nEmpiric Tau: ", tau_info$Empiric_Tau[index])
)
}
label_data <- list(
model1 = create_label_data(subset_data$tau_info, 1),
model2 = create_label_data(subset_data$tau_info, 2),
phi = create_label_data(subset_data$tau_info, 3),
rational = create_label_data(subset_data$tau_info, 4)
)
# Generate graph titles
set_graph_titles_and_paths <- function(subset) {
titles <- list()
if (subset == 1) {
titles <- list(
graph_title_t = "par_n:cu t-stats: Forest Plot of Prior and Posterior Estimates (Subset 1: Original Data)",
graph_title_t2 = "par_n:dist_bound_n t-stats: Forest Plot of Prior and Posterior Estimates (Subset 1: Original Data)",
graph_title_phi = "Phi_e: Forest Plot of Prior and Posterior Estimates (Subset 1: Original Data)",
graph_title_rational = "Coefficient plot: resp_n on par_n with 95% CI divided by rational beta (Subset 1: Original Data)"
)
} else if (subset == 2) {
titles <- list(
graph_title_t = "par_n:cu t-stats: Forest Plot of Prior and Posterior Estimates (Subset 2: Excluding SD=0)",
graph_title_t2 = "par_n:dist_bound_n t-stats: Forest Plot of Prior and Posterior Estimates (Subset 2: Excluding SD=0)",
graph_title_phi = "Phi_e: Forest Plot of Prior and Posterior Estimates (Subset 2: Excluding SD=0)",
graph_title_rational = "Coefficient plot: resp_n on par_n with 95% CI divided by rational beta (Subset 2: Excluding SD=0)"
)
} else if (subset == 3) {
titles <- list(
graph_title_t = "par_n:cu t-stats: Forest Plot of Prior and Posterior Estimates (Subset 3: Excluding Beta<=0)",
graph_title_t2 = "par_n:dist_bound_n t-stats: Forest Plot of Prior and Posterior Estimates (Subset 3: Excluding Beta<=0)",
graph_title_phi = "Phi_e: Forest Plot of Prior and Posterior Estimates (Subset 3: Excluding Beta<=0)",
graph_title_rational = "Coefficient plot: resp_n on par_n with 95% CI divided by rational beta (Subset 3: Excluding Beta<=0)"
)
}
return(titles)
}
graph_details <- set_graph_titles_and_paths(subset)
# Generate Example Plots:
# Create the horizontal forest plot without confidence intervals
t_plot <- ggplot(combined_estimates_t_model1, aes(y = task, x = estimate, fill = type)) +
geom_col(position = position_dodge(width = 0.7), width = 0.6) +
geom_vline(xintercept = 0, linetype = "dashed", size = 0.3) +  # Add thicker line at 0
geom_vline(xintercept = -1.645, linetype = "dashed", size = 0.3, color = "black") +  # Add vertical line at -1.645 (10% significance level)
geom_vline(xintercept = -1.96, linetype = "dashed", size = 0.3, color = "black") +  # Add vertical line at -1.96 (5% significance level)
geom_vline(xintercept = -2.326, linetype = "dashed", size = 0.3, color = "black") +  # Add vertical line at -2.326 (2% significance level)
labs(
title = graph_details$graph_title_t,
x = "Estimate",
y = "Task",
fill = "Estimate Type"
) +
theme_minimal() +
theme(axis.text.y = element_text(angle = 0, hjust = 1, vjust = 0.0, margin = margin(r = 10)),  # Increase distance between experiments
panel.grid.major.y = element_blank(),   # Remove horizontal grid lines for clarity
panel.grid.minor.y = element_blank(),
legend.box = "vertical",
legend.box.just = "left") +
scale_fill_manual(values = c("Prior" = "cadetblue", "Posterior" = "brown2")) +  # Customize colors
geom_label(data = label_data$model1, aes(x = x, y = y, label = label),
hjust = -0.1, vjust = 1.5, size = 3, color = "black", fill = "white", label.size = 0.5)
print(t_plot)
# Create the horizontal forest plot for model2 with confidence intervals
t_plot_model2 <- ggplot(combined_estimates_t_model2, aes(y = task, x = estimate, fill = type)) +
geom_col(position = position_dodge(width = 0.7), width = 0.6) +
geom_vline(xintercept = 0, linetype = "dashed", size = 0.3) +  # Add thicker line at 0
geom_vline(xintercept = -1.645, linetype = "dashed", size = 0.3, color = "black") +  # Add vertical line at -1.645 (10% significance level)
geom_vline(xintercept = -1.96, linetype = "dashed", size = 0.3, color = "black") +  # Add vertical line at -1.96 (5% significance level)
geom_vline(xintercept = -2.326, linetype = "dashed", size = 0.3, color = "black") +  # Add vertical line at -2.326 (2% significance level)
labs(
title = graph_details$graph_title_t2,
x = "Estimate",
y = "Task",
fill = "Estimate Type"
) +
theme_minimal() +
theme(axis.text.y = element_text(angle = 0, hjust = 1, vjust = 0.0, margin = margin(r = 10)),  # Increase distance between experiments
panel.grid.major.y = element_blank(),   # Remove horizontal grid lines for clarity
panel.grid.minor.y = element_blank(),
legend.box = "vertical",
legend.box.just = "left") +
scale_fill_manual(values = c("Prior" = "cadetblue", "Posterior" = "brown2")) +  # Customize colors
geom_label(data = label_data$model2, aes(x = x, y = y, label = label),
hjust = -0.1, vjust = 1.5, size = 3, color = "black", fill = "white", label.size = 0.5)
print(t_plot_model2)
# Create the horizontal forest plot with a thicker line at 0
phi_e_plot <- ggplot(combined_estimates_phi, aes(y = task, x = estimate, fill = type)) +
geom_col(position = position_dodge(width = 0.7), width = 0.6) +
geom_vline(xintercept = 0, linetype = "dashed", size = 0.3) +  # Add thicker line at 0
labs(
title = graph_details$graph_title_phi,
x = "Estimate",
y = "Task",
fill = "Estimate Type"
) +
theme_minimal() +
theme(axis.text.y = element_text(angle = 0, hjust = 1, margin = margin(r = 10)),  # Increase distance between experiments
panel.grid.major.y = element_blank(),   # Remove horizontal grid lines for clarity
panel.grid.minor.y = element_blank(),
legend.box = "vertical",
legend.box.just = "left") +
scale_fill_manual(values = c("Prior" = "cadetblue", "Posterior" = "brown2")) +  # Customize colors
geom_label(data = label_data$phi, aes(x = x, y = y, label = label),
hjust = -0.1, vjust = 1.5, size = 3, color = "black", fill = "white", label.size = 0.5)
print(phi_e_plot)
# Create the horizontal forest plot with confidence intervals
rational_plot <- ggplot(combined_estimates_rational_beta, aes(y = task, x = estimate, color = type)) +
geom_point(position = position_dodge(width = 0.7), size = 3) +
geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0.2, position = position_dodge(width = 0.7)) +  # Add confidence intervals
geom_vline(xintercept = 0, linetype = "dashed", color = "red", size = 0.3) +  # Add thicker red line at 0
geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 0.3) +  # Add thicker red line at 1
labs(
title = graph_details$graph_title_rational,
x = "Estimate",
y = "Task",
color = "Estimate Type"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(angle = 0, hjust = 1, margin = margin(r = 10)),  # Increase distance between experiments
panel.grid.major.y = element_blank(),   # Remove horizontal grid lines for clarity
panel.grid.minor.y = element_blank(),
legend.position = "bottom",
legend.justification = "left"
) +
scale_color_manual(values = c("Prior" = "cadetblue", "Posterior" = "brown2")) +  # Customize colors
geom_label(data = label_data$rational, aes(x = x, y = y, label = label),
hjust = -0.1, vjust = 1.5, size = 3, color = "black", fill = "white", label.size = 0.5)
print(rational_plot)
